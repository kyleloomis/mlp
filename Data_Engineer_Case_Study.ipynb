{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T23:18:28.180865Z",
     "start_time": "2025-03-11T23:18:28.172235Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "import logging\n",
    "from tempfile import NamedTemporaryFile\n",
    "import time\n",
    "import subprocess\n",
    "from math import ceil\n",
    "import requests\n",
    "import gzip\n",
    "import io\n",
    "import re\n",
    "from datetime import datetime"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'requests'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/v6/1rdtx7yx2rz_g687s_jskfkh0000gn/T/ipykernel_50846/1079435211.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0msubprocess\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mmath\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mceil\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 9\u001B[0;31m \u001B[0;32mimport\u001B[0m \u001B[0mrequests\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     10\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mgzip\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mio\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'requests'"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background Information: SEC ADV Filings\n",
    "\n",
    "The SEC Form ADV is a key regulatory document used by investment advisers to register with the U.S. Securities and Exchange Commission (SEC). It serves as a comprehensive disclosure form that provides detailed information about an investment adviser’s business, including its operations, services, and any potential conflicts of interest.\n",
    "\n",
    "**Key Components of the SEC Form ADV:**\n",
    "\n",
    "1. **Part 1A:** This section contains information about the adviser's business, ownership, clients, employees, business practices, affiliations, and any disciplinary events of the adviser or its employees. It also includes details about the private funds managed by the adviser.\n",
    "\n",
    "2. **Part 2A (Brochure):** This section provides a narrative description of the adviser’s business practices, fees, conflicts of interest, and disciplinary information. It is designed to be a plain-English disclosure document that is given to clients.\n",
    "\n",
    "3. **Part 2B (Brochure Supplement):** This section includes information about the advisory personnel on whom clients rely for investment advice, including their education, business experience, and any disciplinary history.\n",
    "\n",
    "**Why is the SEC Form ADV Important?**\n",
    "\n",
    "- **Transparency:** The form promotes transparency by providing clients and regulators with essential information about the adviser’s business practices and any potential conflicts of interest.\n",
    "- **Regulatory Compliance:** Filing the Form ADV is a regulatory requirement for investment advisers, ensuring they operate within the legal framework set by the SEC and state authorities.\n",
    "- **Investor Protection:** By disclosing detailed information about their operations and practices, advisers help protect investors from fraud and misrepresentation.\n",
    "\n",
    "**Private Fund Reporting:**\n",
    "\n",
    "Within the SEC Form ADV, Sections 7.B.(1) and 7.B.(2) are specifically focused on private fund reporting. These sections require advisers to provide detailed information about the private funds they manage or advise, including the fund’s name, type, gross asset value, and regulatory status. This information helps regulators and investors understand the scope and nature of the adviser’s involvement with private funds.\n",
    "\n",
    "**Task Context:**\n",
    "\n",
    "For this task, you will be working with data extracted from SEC ADV filings. You will download metadata and PDFs for specific firms, extract relevant information, and analyze it to identify top-performing funds. This exercise will help you understand how regulatory filings can be used to gather critical information about investment advisers and their managed funds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the metadata"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T22:46:55.958760Z",
     "start_time": "2025-03-11T22:46:55.578361Z"
    }
   },
   "source": [
    "# Set the WorkingDate to the latest date, e.g., Feb 14, 2025\n",
    "WorkingDate = datetime(2025, 2, 14)\n",
    "\n",
    "\n",
    "path = rf\"https://reports.adviserinfo.sec.gov/reports/CompilationReports/IA_FIRM_SEC_Feed_{WorkingDate:%m_%d_%Y}.xml.gz\" \n",
    "\n",
    "response = requests.get(path)\n",
    "\n",
    "# Ensure the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Unzip the content\n",
    "    with gzip.GzipFile(fileobj=io.BytesIO(response.content)) as gz:\n",
    "        #Read the data into a dataframe\n",
    "        df = pd.read_xml(gz, xpath='//Info')\n",
    "else: print(f\"Failed to download the file. Status code: {response.status_code}\")\n",
    "\n",
    "# Create a column with paths for the pdfs\n",
    "df['DownloadPath'] = df['FirmCrdNb'].apply(lambda x: f\"https://reports.adviserinfo.sec.gov/reports/ADV/{x}/PDF/{x}.pdf\")\n",
    "df.set_index('FirmCrdNb', inplace = True)\n",
    "\n",
    "df"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datetime' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/v6/1rdtx7yx2rz_g687s_jskfkh0000gn/T/ipykernel_50846/198788955.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# Set the WorkingDate to the latest date, e.g., Feb 14, 2025\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mWorkingDate\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdatetime\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m2025\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m2\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m14\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mpath\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34mrf\"https://reports.adviserinfo.sec.gov/reports/CompilationReports/IA_FIRM_SEC_Feed_{WorkingDate:%m_%d_%Y}.xml.gz\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'datetime' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the PDF text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory to save the downloaded files\n",
    "save_dir = input_dir\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "count = 0 # number of files skipped\n",
    "\n",
    "# Setup log to capture if any files failed to download:\n",
    "logging.basicConfig(filename='download_logs.log', level = logging.INFO,\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for url in df['DownloadPath']: \n",
    "    FileName = url.split('/')[-1]\n",
    "    save_path = os.path.join(save_dir, FileName)\n",
    "    \n",
    "    # Check if the file already exists\n",
    "    if os.path.isfile(save_path):\n",
    "        count += 1\n",
    "        logging.info(f\"File {FileName} already exists. Skipping download.\")\n",
    "        continue\n",
    "\n",
    "    # Create the request\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        with open(save_path, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        logging.info(f\"Downloaded {FileName}\")\n",
    "    else:\n",
    "        logging.error(f\"Failed to download {FileName}. Status code: {response.status_code}\")\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "duration_minutes = (end_time - start_time) / 60\n",
    "\n",
    "# Log the total time taken in minutes \n",
    "logging.info(f\"Completed the download process in {duration_minutes:.2f} minutes.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download Metadata and PDFs (Estimated Time: 30-45 minutes):\n",
    "Using the starter code provided, download the metadata and PDFs for the following FirmCrdNb values. Use the provided URLs to download the files and save them locally. Implement error handling and logging :\n",
    "* 160882\n",
    "* 160021\n",
    "* 1679500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extract and Store Information (Estimated Time: 1-1.5 hours):\n",
    "* Task: Extract specific information from the downloaded PDFs and store it in a local SQLite database.\n",
    "* Details: Extract fields such as FirmCrdNb, SECNb, Business Name, Full Legal Name, Address, Phone Number, Compensation Arrangements, Number of employees performing investment advisory functions, Type of Client and Amount of Regulatory Assets Under Management, Names of Private Fund and Private Fund Identification Number, and Signatory of the PDF.\n",
    "* In practice, you will deal with tens of thousands of files. Your code should systematically parse the text and extract the relevant information, as scalability is an important factor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Transformation and Analysis (Estimated Time: 30-45 minutes):\n",
    "* Task: Perform data transformation and analysis using Pandas.\n",
    "* Details: Clean and transform the extracted data, and perform basic analysis such as identifying the top-performing funds based on specific criteria (e.g., assets under management)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate Excel File (Estimated Time: 15-30 minutes):\n",
    "* Task: Extract the following information from the SQLite database and output it in an **Excel file**. Keep in mind that this excel file will be ultimately used by BD recruiters who are considered non-techinical users:\n",
    "* FirmCrdNb\n",
    "* SECNb\n",
    "* Business Name\n",
    "* Full Legal Name\n",
    "* Address\n",
    "* Phone Number\n",
    "* Compensation Arrangements\n",
    "* Number of employees performing investment advisory functions, including research\n",
    "* Type of Client and Amount of Regulatory Assets Under Management\n",
    "* Names of Private Fund and Private Fund Identification Number\n",
    "* Signatory of the PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Scalability and Performance (Discussion - Estimated Time: 15-30 minutes):\n",
    "* Task: Optimize the data pipeline for performance.\n",
    "* Details: Write a brief explanation of how you would handle scalability and performance issues if the dataset were significantly larger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Integration with External Systems (Estimated Time: 1-1.5 hours):\n",
    "* Task: Simulate integration with an external system using Fast APIs.\n",
    "* Details: Write a Python script to fetch additional data from a mock API from your SQLite database using standard Python frameworks and data models. Create three GET and PUSH endpoints and demonstrate data quality checks and validations. Provide two tests for each call. Consider and handle potential edge cases. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Automated Testing and Data Quality (Discussion - Estimated Time: 15-30 minutes):\n",
    "* Task: Write a brief explanation of how you would implement automated testing and ensure data quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Identify Top Performing Funds (Discussion - Estimated Time: 15-30 minutes):\n",
    "* Describe how you would use the information above to identify top-performing funds.\n",
    "* List any questions you would ask regarding the task.\n",
    "* Specify any additional information you would need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Data Visualization (Optional - Estimated Time: 30-45 minutes (if included)):\n",
    "* Task: Create visualizations using a Python library such as Matplotlib or Seaborn.\n",
    "* Details: Generate plots to visualize key metrics and insights from the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [NOTE] Please do not spend more than 6 hours on this task. Also, provide the time it took you to complete it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
